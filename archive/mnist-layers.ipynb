{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e386b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.example_libraries.optimizers as jopt\n",
    "import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "jax.config.update(\"jax_debug_nans\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f09884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert jax.devices()[0].device_kind == 'NVIDIA GeForce RTX 3060'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4600294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(vals):\n",
    "    mean = jnp.average(vals, axis=1, keepdims=True)\n",
    "    std = jnp.std(vals, axis=1, keepdims=True)\n",
    "    return (vals - mean) / (0.0001 + std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d24d337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = mnist.train_images()\n",
    "labels = mnist.train_labels()\n",
    "labels_vec = jax.nn.one_hot(labels, 10)\n",
    "images_vec = layer_norm(images.reshape((-1, 784)))\n",
    "\n",
    "order = np.array(range(images_vec.shape[1]))\n",
    "npr.RandomState(0).shuffle(order)\n",
    "images_vec = images_vec[:, order]\n",
    "\n",
    "test_img = layer_norm(mnist.test_images().reshape((-1, 784)))[:, order]\n",
    "test_lbl = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62241a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_params_old():\n",
    "    scale = 1/255.0\n",
    "    rng = npr.RandomState(0)\n",
    "    bias = scale * 0.001\n",
    "    out = [scale*rng.randn(784, width), bias*rng.randn(width)]\n",
    "    for i in range(height):\n",
    "        out += [scale*rng.randn(width, width), bias*rng.randn(width)]\n",
    "    out += [scale*rng.randn(width, 10), bias*rng.randn(10)]\n",
    "    return out\n",
    "\n",
    "def init_params():\n",
    "    def he_init(rng, dim1, dim2):\n",
    "        # https://mmuratarat.github.io/2019-02-25/xavier-glorot-he-weight-init\n",
    "        # why do i need 0.1??? something is wrong\n",
    "        return 0.1*rng.normal(0.0, math.sqrt(4/(dim1+dim2)), (dim1, dim2))\n",
    "    bias = 0.01\n",
    "    rng = npr.RandomState(0)\n",
    "    out = [he_init(rng, 784, width), bias*rng.randn(width)]\n",
    "    for i in range(height):\n",
    "        out += [he_init(rng, width, width), bias*rng.randn(width)]\n",
    "    out += [he_init(rng, width, 10), bias*rng.randn(10)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c2ab87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nonlinearlity = jax.nn.relu  # gelu, relu6, selu bad -- they don't support as many layers\n",
    "'''\n",
    "issue is that we seem to have better depth with relu, up to 7 layers\n",
    "  --> fix init\n",
    "  --> change learning rate\n",
    "\n",
    "take regular snapshots of paramters, sometimes a high learning rate breaks need to change\n",
    "'''\n",
    "def predict(params, images):\n",
    "    vals = images\n",
    "    vals = nonlinearlity(jnp.dot(vals, params[0]) + params[1])\n",
    "    for i in range(height):\n",
    "        vals = layer_norm(vals)\n",
    "        vals = nonlinearlity(jnp.dot(vals, params[2+i*2]) + params[3+i*2]) + vals\n",
    "    vals = layer_norm(vals)\n",
    "    vals = jnp.dot(vals, params[2+height*2]) + params[3+height*2]\n",
    "    return jax.nn.softmax(vals)\n",
    "\n",
    "def loss(params, images, labels):\n",
    "    guess = predict(params, images)\n",
    "    return -jnp.mean(jnp.log(jnp.sum(guess * labels, axis=1)))\n",
    "# regularization bad why: + 0.00001 * sum(jnp.sum(jnp.power(p, 2)) for p in params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5baeff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param count = 512510 [196000, 250, 62500, 250, 62500, 250, 62500, 250, 62500, 250, 62500, 250, 2500, 10]\n",
      "000 0.263 / 0.270\n",
      "001 0.358 / 0.368\n",
      "002 0.417 / 0.426\n",
      "003 0.470 / 0.476\n",
      "004 0.517 / 0.526\n",
      "005 0.556 / 0.568\n",
      "006 0.595 / 0.605\n",
      "007 0.624 / 0.635\n",
      "008 0.643 / 0.651\n",
      "009 0.663 / 0.671\n",
      "6584 0.991 / 0.978\n",
      "10000 0.994 / 0.981\n"
     ]
    }
   ],
   "source": [
    "width = 250\n",
    "height = 5\n",
    "params = init_params()\n",
    "print(f'param count = {sum(p.size for p in params)} {[p.size for p in params]}')\n",
    "\n",
    "batch_size = (50,)\n",
    "step_size = 0.0001\n",
    "steps = 10000\n",
    "\n",
    "opt_init, opt_update, get_params = jopt.adam(step_size)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "@jax.jit\n",
    "def update(i, opt_state, images_vec_batch, labels_vec_batch):\n",
    "    params = get_params(opt_state)\n",
    "    grads = jax.grad(loss)(params, images_vec_batch, labels_vec_batch)\n",
    "    # jax.debug.print('{grads}', grads=grads)\n",
    "    return opt_update(i, grads, opt_state)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "rnd = jax.random.split(jax.random.PRNGKey(0), steps)\n",
    "for i in range(0, steps+1):\n",
    "    images_vec_batch = jax.random.choice(rnd[i], images_vec, batch_size)\n",
    "    labels_vec_batch = jax.random.choice(rnd[i], labels_vec, batch_size)\n",
    "    opt_state = update(i, opt_state, images_vec_batch, labels_vec_batch)\n",
    "    if i < 10 or (datetime.datetime.now() - t).total_seconds() > 5.0 or i == steps:\n",
    "        params = get_params(opt_state)\n",
    "        test = jnp.mean(jnp.argmax(predict(params, test_img), axis=1) == test_lbl)\n",
    "        accuracy = jnp.mean(jnp.argmax(predict(params, images_vec), axis=1) == labels)\n",
    "        print(f'{i:03d} {accuracy:0.3f} / {test:0.3f}')\n",
    "        t = datetime.datetime.now()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
