{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c683e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.example_libraries.optimizers as jopt\n",
    "import haiku as hk\n",
    "import mnist\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import dataclasses\n",
    "import optax\n",
    "\n",
    "from typing import Optional, NamedTuple\n",
    "\n",
    "jax.config.update(\"jax_debug_nans\", True)\n",
    "jnp.set_printoptions(suppress=True, precision=2, floatmode='fixed')\n",
    "flt = jnp.float32\n",
    "assert jax.devices()[0].device_kind == 'NVIDIA GeForce RTX 3060'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1fd73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.array(range(784))\n",
    "np.random.RandomState(0).shuffle(order)\n",
    "\n",
    "train_images = mnist.train_images().reshape((-1, 784))[:, order] / 255\n",
    "train_labels = mnist.train_labels()\n",
    "train_labels_hot = jax.nn.one_hot(train_labels, 10)\n",
    "\n",
    "test_img = mnist.test_images().reshape((-1, 784))[:, order] / 255\n",
    "test_lbl = mnist.test_labels()\n",
    "\n",
    "# specific processing for this model\n",
    "train_images = jnp.expand_dims(train_images, axis=2)\n",
    "test_img = jnp.expand_dims(test_img, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2e926b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class DLN(hk.Module):\n",
    "    head_len: int\n",
    "    input_dim: int\n",
    "    seq_len: int\n",
    "    name: Optional[str] = None\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        x # [B, seq_len, input_dim]\n",
    "    ):\n",
    "        k = self.head_len * self.input_dim\n",
    "        size = hk.get_parameter('size', shape=[k], dtype=flt, init=hk.initializers.RandomNormal())\n",
    "        theta = hk.get_parameter('theta', shape=[k], dtype=flt, init=hk.initializers.RandomNormal(jnp.pi))\n",
    "        weights = hk.get_parameter('weights', shape=[k,k], dtype=flt, init=hk.initializers.TruncatedNormal(stddev=1./jnp.sqrt(k)))\n",
    "        z = -jnp.square(size) + 1j * theta\n",
    "        \n",
    "        def combine(a, b):\n",
    "            pos = a[:,:,:,0] + b[:,:,:,0]\n",
    "            val = a[:,:,:,1] * jnp.exp(z * b[:,:,:,0]) + b[:,:,:,1]\n",
    "            return jnp.stack([pos, val], axis=-1)\n",
    "        x = jnp.tile(x, (1, 1, self.head_len))  # [B, seq_len, head_len * input_dim]\n",
    "        x = jnp.stack([jnp.ones(x.shape), x], axis=-1, dtype=complex)  # [B, seq_len, head_len * input_dim, 2]\n",
    "        x = jax.lax.associative_scan(combine, x, axis=1)[:,:,:,1]  # [B, seq_len, head_len * input_dim]\n",
    "        x = (x @ weights)  # [B, seq_len, head_len * input_dim]\n",
    "        x = jnp.real(x) * jnp.imag(x)  # [B, seq_len, head_len * input_dim]\n",
    "        return x\n",
    "\n",
    "@hk.transform\n",
    "def model(x):\n",
    "    middle_len = 20\n",
    "    x = DLN(head_len=middle_len, input_dim=1, seq_len=784, name='dln_root')(x)  # [B, seq_len, head_len * input_dim]\n",
    "    x = hk.Linear(output_size=middle_len)(x) + x  # [B, seq_len, middle_len]\n",
    "    x = jax.nn.relu(x)\n",
    "    for depth in range(3):\n",
    "        x = DLN(head_len=1, input_dim=middle_len, seq_len=784, name=f'dln_{depth}')(x)  # [B, seq_len, head_len * middle_len]\n",
    "        x = hk.Linear(output_size=middle_len)(x) + x  # [B, seq_len, middle_len]\n",
    "        x = jax.nn.relu(x)\n",
    "    # x = DLN(head_len=10, input_dim=middle_len, seq_len=784, name='dln')(x)  # [B, seq_len, head_len * input_dim]\n",
    "    # x = hk.dropout(hk.next_rng_key(), 0.2, x)\n",
    "    x = x[:, -1, :]  # [B, middle_len]\n",
    "    x = hk.Linear(output_size=10, with_bias=True)(x)  # [B, 10]\n",
    "    x = jax.nn.softmax(x)\n",
    "    return x\n",
    "\n",
    "def loss(params: hk.Params, rnd, inputs, outputs):\n",
    "    guess = model.apply(params, rnd, inputs)\n",
    "    return -jnp.mean(jnp.log(0.001+jnp.sum(guess * outputs, axis=1)))\n",
    "\n",
    "a = model.init(x=train_images[0:5,:], rng=jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe59604",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 6.04 0.16 / 0.14\n",
      "0001 5.16\n",
      "0401 2.58\n",
      "0808 2.29\n",
      "1215 2.26 0.22 / 0.26\n",
      "1622 2.14\n",
      "2024 2.23\n",
      "2425 2.17\n",
      "2831 2.18 0.22 / 0.20\n",
      "3238 2.29\n",
      "3645 1.93\n",
      "4043 1.95\n",
      "4448 2.00 0.36 / 0.26\n",
      "4855 1.84\n",
      "5262 1.84\n",
      "5669 1.78\n",
      "6075 1.65 0.56 / 0.40\n",
      "6482 1.45\n",
      "6889 1.44\n",
      "7296 0.89\n",
      "7703 0.97 0.60 / 0.58\n",
      "8110 0.82\n",
      "8517 0.45\n",
      "8924 0.87\n",
      "9330 0.71 0.70 / 0.60\n",
      "9732 0.72\n",
      "interrupt 9773 0.755 / 0.685 (done)\n"
     ]
    }
   ],
   "source": [
    "class State(NamedTuple):\n",
    "    params: hk.Params\n",
    "    opt_state: optax.OptState\n",
    "    loss_value: float\n",
    "\n",
    "@jax.jit\n",
    "def update(state: State, rnd, inputs, outputs) -> State:\n",
    "    loss_value, grads = jax.value_and_grad(loss)(state.params, rnd, inputs, outputs)\n",
    "    updates, opt_state = optimizer.update(grads, state.opt_state)\n",
    "    return State(optax.apply_updates(state.params, updates), opt_state, loss_value)\n",
    "\n",
    "def init(optimizer) -> State:\n",
    "    sample = train_images[0:5,:]\n",
    "    init_params = model.init(jax.random.PRNGKey(0), sample)\n",
    "    return State(init_params, optimizer.init(init_params), -1.0)\n",
    "\n",
    "optimizer = optax.adam(1e-3)\n",
    "state = init(optimizer)\n",
    "t = u = datetime.datetime.now()\n",
    "steps = 100000\n",
    "batch_size = (30,)\n",
    "rnd = jax.random.split(jax.random.PRNGKey(0), steps)\n",
    "\n",
    "try:\n",
    "    for i in range(0, steps):\n",
    "        inputs = jax.random.choice(rnd[i], train_images, batch_size)\n",
    "        outputs = jax.random.choice(rnd[i], train_labels_hot, batch_size)\n",
    "        state = update(state, rnd[i], inputs, outputs)\n",
    "        if i == 0 or (datetime.datetime.now() - t).total_seconds() > 5.0:\n",
    "            if i == 0 or (datetime.datetime.now() - u).total_seconds() > 20.0:\n",
    "                print(f'{i:04d} {state.loss_value:0.2f} ', end='')\n",
    "                accuracy = jnp.mean(jnp.argmax(model.apply(state.params, rnd[i], train_images[0:50,:]), axis=1) == train_labels[0:50])\n",
    "                test = jnp.mean(jnp.argmax(model.apply(state.params, rnd[i], test_img[0:50,:]), axis=1) == test_lbl[0:50])\n",
    "                print(f'{accuracy:0.2f} / {test:0.2f}')\n",
    "                u = datetime.datetime.now()\n",
    "            else:\n",
    "                print(f'{i:04d} {state.loss_value:0.2f}')\n",
    "            t = datetime.datetime.now()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f'interrupt {i:03d} ', end='')\n",
    "\n",
    "accuracy = jnp.mean(jnp.argmax(model.apply(state.params, rnd[i], train_images[0:200,:]), axis=1) == train_labels[0:200])\n",
    "test = jnp.mean(jnp.argmax(model.apply(state.params, rnd[i], test_img[0:200,:]), axis=1) == test_lbl[0:200])\n",
    "print(f'{accuracy:0.3f} / {test:0.3f} (done)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
