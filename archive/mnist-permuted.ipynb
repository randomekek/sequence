{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323ec6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.example_libraries.optimizers as jopt\n",
    "import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "jax.config.update(\"jax_debug_nans\", False)\n",
    "float_type = jnp.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6acddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jax.devices()[0].device_kind == 'NVIDIA GeForce RTX 3060'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a67958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(vals):\n",
    "    vals = jnp.array(vals, dtype=float_type)\n",
    "    mean = jnp.average(vals, axis=1, keepdims=True)\n",
    "    std = jnp.std(vals, axis=1, keepdims=True)\n",
    "    return (vals - mean) / (0.0001 + std)\n",
    "\n",
    "def shuf(a, axis):\n",
    "    return jnp.array(np.random.rand(*a.shape).argsort(axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27eb3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_data_with_coord(data):\n",
    "    idx = shuf(data, axis=1)\n",
    "    shufdata = jnp.take_along_axis(data, idx, axis=1)\n",
    "    coord = jnp.divmod(idx, 28) # 28*28 = 784\n",
    "    a = jnp.array([shufdata, coord[0]/28.0, coord[1]/28.0], dtype=float_type)\n",
    "    # unshuffled with zeros: a = jnp.array([data, coord[0]*0.0+0.1, coord[1]*0.0+0.1], dtype=float_type)\n",
    "    return a.swapaxes(0, 1).swapaxes(1, 2).reshape(data.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6216f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = mnist.train_images()\n",
    "labels = mnist.train_labels()\n",
    "labels_vec = jax.nn.one_hot(labels, 10)\n",
    "images_vec = permute_data_with_coord(layer_norm(images.reshape((-1, 784))))\n",
    "\n",
    "test_img = permute_data_with_coord(layer_norm(mnist.test_images().reshape((-1, 784))))\n",
    "test_lbl = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84523fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    def he_init(rng, dim1, dim2):\n",
    "        # https://mmuratarat.github.io/2019-02-25/xavier-glorot-he-weight-init\n",
    "        # why do i need 0.1??? something is wrong\n",
    "        return 0.1*rng.normal(0.0, math.sqrt(4/(dim1+dim2)), (dim1, dim2))\n",
    "    bias = 0.01\n",
    "    rng = npr.RandomState(0)\n",
    "    out = [he_init(rng, 784*3, width), bias*rng.randn(width)]\n",
    "    for i in range(height):\n",
    "        out += [he_init(rng, width, width), bias*rng.randn(width)]\n",
    "    out += [he_init(rng, width, 10), bias*rng.randn(10)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23b39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinearlity = jax.nn.relu  # gelu, relu6, selu bad -- they don't support as many layers\n",
    "'''\n",
    "issue is that we seem to have better depth with relu, up to 7 layers\n",
    "  --> fix init\n",
    "  --> change learning rate\n",
    "\n",
    "take regular snapshots of paramters, sometimes a high learning rate breaks need to change\n",
    "\n",
    "as long as the vectors are relatively correctly scaled it works (each group of similar variance)\n",
    "'''\n",
    "\n",
    "def attention(params, i, vals):\n",
    "    return jnp.dot(params[i], vals) * jnp.transpose(jnp.dot(params[i+1], vals))\n",
    "\n",
    "def predict(params, images):\n",
    "    vals = images\n",
    "    vals = nonlinearlity(jnp.dot(vals, params[0]) + params[1])\n",
    "    for i in range(height):\n",
    "        vals = layer_norm(vals)\n",
    "        vals = nonlinearlity(jnp.dot(vals, params[2+i*2]) + params[3+i*2]) + vals\n",
    "    vals = layer_norm(vals)\n",
    "    vals = jnp.dot(vals, params[2+height*2]) + params[3+height*2]\n",
    "    return jax.nn.softmax(vals)\n",
    "\n",
    "def loss(params, images, labels):\n",
    "    guess = predict(params, images)\n",
    "    return -jnp.mean(jnp.log(jnp.sum(guess * labels, axis=1)))\n",
    "# regularization bad why: + 0.00001 * sum(jnp.sum(jnp.power(p, 2)) for p in params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc9e0413",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param count = 22383010 [2352000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 1000000, 1000, 10000, 10]\n",
      "000 0.111 / 0.110\n",
      "001 0.103 / 0.102\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m params \u001b[38;5;241m=\u001b[39m get_params(opt_state)\n\u001b[1;32m     28\u001b[0m test \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39margmax(predict(params, test_img), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m test_lbl)\n\u001b[0;32m---> 29\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39margmax(\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_vec\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m labels)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m t \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(params, images)\u001b[0m\n\u001b[1;32m     17\u001b[0m vals \u001b[38;5;241m=\u001b[39m nonlinearlity(jnp\u001b[38;5;241m.\u001b[39mdot(vals, params[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m params[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(height):\n\u001b[0;32m---> 19\u001b[0m     vals \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     vals \u001b[38;5;241m=\u001b[39m nonlinearlity(jnp\u001b[38;5;241m.\u001b[39mdot(vals, params[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mi\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m+\u001b[39m params[\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m+\u001b[39mi\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m+\u001b[39m vals\n\u001b[1;32m     21\u001b[0m vals \u001b[38;5;241m=\u001b[39m layer_norm(vals)\n",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m      3\u001b[0m mean \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39maverage(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m std \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mstd(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (vals \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mnist/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:4948\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4946\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m   4947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m-> 4948\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _rejected_binop_types):\n\u001b[1;32m   4950\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported operand type(s) for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopchar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4951\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "width = 1000\n",
    "height = 20\n",
    "params = init_params()\n",
    "print(f'param count = {sum(p.size for p in params)} {[p.size for p in params]}')\n",
    "\n",
    "batch_size = (60,)\n",
    "step_size = 0.0001\n",
    "steps = 10000\n",
    "\n",
    "opt_init, opt_update, get_params = jopt.adam(step_size)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "@jax.jit\n",
    "def update(i, opt_state, images_vec_batch, labels_vec_batch):\n",
    "    params = get_params(opt_state)\n",
    "    grads = jax.grad(loss)(params, images_vec_batch, labels_vec_batch)\n",
    "    # jax.debug.print('{x}', x=jax.random.choice(rnd, labels_vec, batch_size))\n",
    "    return opt_update(i, grads, opt_state)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "rnd = jax.random.split(jax.random.PRNGKey(0), steps+1)\n",
    "for i in range(0, steps+1):\n",
    "    images_vec_batch = jax.random.choice(rnd[i], images_vec, batch_size)\n",
    "    labels_vec_batch = jax.random.choice(rnd[i], labels_vec, batch_size)\n",
    "    opt_state = update(i, opt_state, images_vec_batch, labels_vec_batch)\n",
    "    if i < 10 or (datetime.datetime.now() - t).total_seconds() > 5 or i == steps:\n",
    "        params = get_params(opt_state)\n",
    "        test = jnp.mean(jnp.argmax(predict(params, test_img), axis=1) == test_lbl)\n",
    "        accuracy = jnp.mean(jnp.argmax(predict(params, images_vec), axis=1) == labels)\n",
    "        print(f'{i:03d} {accuracy:0.3f} / {test:0.3f}')\n",
    "        t = datetime.datetime.now()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
